PyKEEN 的 `HPOPipeline` 是一个方便的工具，用于执行超参数优化 (Hyperparameter Optimization, HPO)，帮助选择最优的模型参数配置。以下是使用 `HPOPipeline` 的详细步骤和代码示例：

---

### 1. **安装依赖**
确保安装了 PyKEEN：
```bash
pip install pykeen
```

---

### 2. **HPOPipeline 的基本原理**
`HPOPipeline` 利用超参数搜索算法（如随机搜索、网格搜索或贝叶斯优化）来优化模型参数。其核心流程包括：
- 定义模型、数据集和超参数搜索空间。
- 自动尝试不同参数组合，基于验证集评估性能。
- 返回最优的参数配置及对应模型。

---

### 3. **HPOPipeline 示例代码**

#### 3.1 基本使用
```python
from pykeen.hpo import hpo_pipeline

# 使用 HPOPipeline 进行超参数优化
result = hpo_pipeline(
    model="TransE",
    dataset="FB15k-237",  # 内置数据集或自定义数据集路径
    training_kwargs_ranges={
        "num_epochs": {"type": "int", "low": 50, "high": 200},
        "batch_size": {"type": "int", "low": 128, "high": 512},
    },
    model_kwargs_ranges={
        "embedding_dim": {"type": "int", "low": 50, "high": 300},
        "margin": {"type": "float", "low": 1.0, "high": 5.0},
    },
    optimizer_kwargs_ranges={
        "lr": {"type": "float", "low": 1e-4, "high": 1e-1, "scale": "log"},
    },
    n_trials=50,  # 超参数搜索的次数
)

# 输出最优结果
print("Best parameters:", result.best_config)
print("Best metric value:", result.best_metric_value)
```

#### 3.2 自定义数据集
如果使用自己的知识图谱数据集，需要将数据集存储为 PyKEEN 支持的格式：
- **标准格式**：`train.txt`, `test.txt`, `valid.txt`（每行一个三元组 `head relation tail`）。
- 指定数据集路径：
```python
result = hpo_pipeline(
    model="TransE",
    dataset="path/to/dataset",  # 数据集路径
    ...
)
```

#### 3.3 使用贝叶斯优化
PyKEEN 支持多种优化算法，默认使用 **Optuna** 进行贝叶斯优化。如果需要修改，可以传入 `sampler` 或 `pruner` 参数。例如：
```python
from optuna.samplers import TPESampler

result = hpo_pipeline(
    model="TransE",
    dataset="FB15k-237",
    sampler=TPESampler(seed=42),  # 使用 TPE 贝叶斯优化
    n_trials=50,
)
```

---

### 4. **定义参数搜索空间**

#### 4.1 定义范围类型
PyKEEN 支持以下类型的参数范围：
- `int`: 整数范围。
- `float`: 浮点数范围。
- `categorical`: 离散值列表。
- `scale`: 可选值 `linear` 或 `log`。

#### 4.2 示例
```python
# 示例参数范围
model_kwargs_ranges = {
    "embedding_dim": {"type": "int", "low": 50, "high": 300},  # 整数范围
    "margin": {"type": "float", "low": 1.0, "high": 5.0},      # 浮点数范围
}

optimizer_kwargs_ranges = {
    "lr": {"type": "float", "low": 1e-4, "high": 1e-1, "scale": "log"},  # 学习率（对数尺度）
}

training_kwargs_ranges = {
    "num_epochs": {"type": "int", "low": 50, "high": 200},  # 训练轮数
    "batch_size": {"type": "int", "low": 128, "high": 512},  # 批量大小
}
```

---

### 5. **输出结果和模型保存**

#### 5.1 最优配置
`HPOPipeline` 的结果对象中包含以下重要信息：
- `result.best_config`: 最优参数配置。
- `result.best_pipeline_result`: 最优参数配置下的模型训练结果。
- `result.best_model`: 最优参数下训练好的模型。

#### 5.2 保存模型
```python
# 获取最优模型并保存
best_model = result.best_model
best_model.save("best_transe_model.pkl")
```

---

### 6. **与向量数据库集成**
可以将最优模型生成的实体和关系嵌入保存到向量数据库（如 Milvus）：
```python
import numpy as np
from pymilvus import Collection, utility

# 加载最优模型的实体嵌入
entity_embeddings = result.best_model.entity_representations[0]().detach().numpy()

# 向 Milvus 写入实体嵌入
collection = Collection("entity_embeddings")
collection.insert(entity_embeddings.tolist())
```

---

### 7. **定期调用 HPOPipeline**
将 `HPOPipeline` 集成到定期任务（例如通过 FastAPI 定期更新）：
```python
from fastapi import FastAPI
from apscheduler.schedulers.background import BackgroundScheduler

app = FastAPI()

def update_model():
    result = hpo_pipeline(
        model="TransE",
        dataset="path/to/dataset",
        n_trials=50,
    )
    result.best_model.save("best_transe_model.pkl")

scheduler = BackgroundScheduler()
scheduler.add_job(update_model, "interval", days=7)  # 每 7 天重新优化并更新模型
scheduler.start()

@app.get("/")
async def read_root():
    return {"status": "running"}
```

---

通过上述方法，您可以灵活地使用 PyKEEN 的 `HPOPipeline` 进行参数优化，并将其集成到您的应用中。
